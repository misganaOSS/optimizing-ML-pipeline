# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
In this problem, we are told to evaluate and compare the performance of 2 models where one is generated by HyperdriveRun and the other one is generated by AutoML.The dataset we used contains data about the bank customers. By analyzing the features of the data, our learning algorithm needs to predict whether the marketing department of the bank will call the specific customer or not.

As It is a binary classification problem, we choose to use **Logistic Regression** to classify.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**\
In this pipeline architecture,in the **train.py** script, we used the the [dataset](https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv) of 32950 customers each containing 20 features and 1 label to classify whether the marketing department of the bank will call the specific customer or not. We used **RandomParameterSampling** to tune the hyperparameter, **BanditPolicy** as an early termination policy and **scikit learn(SKLearn)** as estimator. As our classification algorithm was **logistic regression**, we used **accuracy** as primary metric name with the goal to **maximize** the metric.\
**What are the benefits of the parameter sampler you chose?**\
We choose Random Parameter Sampling because Random sampling supports discrete and continuous hyperparameters. It supports early termination of low-performance runs and hyperparameter values are randomly selected from the defined search space.\
**What are the benefits of the early stopping policy you chose?**\
We choose Bandit as early stopping policy because BanditPolicy terminates runs where the primary metric is not within the specified slack factor/slack amount compared to the best performing run.
## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
We provide **classification** as task, **accuracy** as primary metric, training data, label name and 3 fold cross validation. After 50 iteratiions generated by **AutoML**, it gives us **Voting Ensemble** as the model with **91.61%** of accuracy.
## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
